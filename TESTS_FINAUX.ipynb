{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protocole Expérimental pour Tester les Méthodes d'Extraction de Mots-Clés\n",
    "\n",
    "## Objectif\n",
    "Comparer les mots-clés extraits par différentes méthodes d'extraction à des commentaires d'utilisateurs existants pour évaluer leur pertinence et leur utilité dans l'explication des recommandations de jeux.\n",
    "\n",
    "## Étapes du Protocole\n",
    "\n",
    "### 1. Préparation des Données\n",
    "- **Pretraitement des données, initialisation et entraînement de l'algorithme de recommandation**\n",
    "- **Nettoyage des Commentaires** : Application des techniques de prétraitement telles que la suppression des stop-words, la ponctuation, et la lemmatisation/stemmatisation.\n",
    "\n",
    "### 2. Méthodes d'Extraction\n",
    "- **Méthodes à Tester** :\n",
    "    - Baseline (Comptage de mots fréquents)\n",
    "    - TF-IDF\n",
    "    - LDA\n",
    "    - TextRank\n",
    "    - YAKE\n",
    "    - RAKE\n",
    "    - KeyBERT\n",
    "- **Extraction de Mots-Clés** : Application de chaque méthode sur les commentaires sélectionnés pour extraire les mots-clés.\n",
    "\n",
    "### 3. Simulation des Explications\n",
    "- **Génération des Explications** : Pour chaque méthode, affichage des mots-clés extraits.\n",
    "- **Correspondance avec les Commentaires Réels** : Comparaison des mots-clés extraits à ceux présents dans les commentaires réels des utilisateurs pour évaluer leur pertinence et leur alignement.\n",
    "\n",
    "### 4. Évaluation de la Pertinence\n",
    "- **Annotation Humaine** : Nous allons noter nous mêmes la pertinence des mots clés sur une echelle de 0 à 5.\n",
    "- **Métriques de Performance** :\n",
    "    - **Précision** : Pourcentage de mots-clés pertinents parmi ceux extraits.\n",
    "    - **Rappel** : Pourcentage de mots-clés pertinents identifiés parmi ceux présents dans les commentaires.\n",
    "    - **F1-Score** : Combinaison harmonique de la précision et du rappel.\n",
    "\n",
    "### 5. Analyse des Résultats\n",
    "- **Comparaison des Méthodes** : Comparaison des scores de précision, de rappel et de F1-score pour chaque méthode. Analyse des feedbacks qualitatifs pour identifier les points forts et les faiblesses de chaque méthode.\n",
    "- **Visualisation des Données** : Graphiques pour représenter les performances des différentes méthodes (par exemple, diagrammes en barres, nuages de mots, etc.).\n",
    "\n",
    "### 6. Interprétation et Recommandations\n",
    "- **Synthèse des Résultats** : Tableau des résultats quantitatifs et qualitatifs pour chaque méthode.\n",
    "- **Suggestions d'Améliorations** : Ajustements ou combinaisons de méthodes pour améliorer davantage l'extraction de mots-clés et la génération d'explications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/martin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/martin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from explication import *\n",
    "from methodes_nlp import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "reco = RecommendationSystem(\"BDD/avis_sans_outliers.csv\")\n",
    "reco.train_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = reco.get_top_comments_filtres('Monsieur Guillaume','Mariposas',5,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Méthodes d'Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BASELINE (Mots les plus fréquents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['faire', 'jeu', 'papillon', 'avoir', 'si', 'plus', 'aller', 'pouvoir', 'autre', 'tout', 'mariposer', 'variante', 'donc', 'carte', 'tour', 'pion', 'très', 'vraiment', 'bien', 'courbe', 'bon', 'migration', 'point', 'sembler', 'gagner', 'essayer', 'falloir', 'score', 'retourner', 'simple', 'niveau', 'progression', 'faciliter', 'cycle', 'vie', 'saisonnier', 'mexiqu', 'québec', 'ramener', 'scorer', 'maximum', 'visiter', 'proche', 'nord', 'revenir', 'dare', 'technique', 'coup', 'moins', 'rendre', 'course', 'trop', 'quand', 'encore', 'objectif', 'tenter', 'moment', 'lorsque', 'reste', 'deux', 'mode', 'partie', 'règle', 'familial', 'cach', 'jouer', 'mariposa', 'envie', 'réfléchir', 'joli', 'optimiser', 'déplacement', 'naissance', 'ville', 'voyage', 'départ', 'tension', 'embêter', 'difficile', 'déterminer', 'concevoir', 'particulier', 'devenir', 'utiliser', 'rallonger', 'saison', 'expliquer', 'sensé', 'organiser', 'monarque', 'poindre', 'atteindre', 'systématiquement', 'valider', 'parfaitement', 'arrêter', 'moitié', 'chemin', 'plein', 'façon']\n"
     ]
    }
   ],
   "source": [
    "print(baseline(comments,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['faire', 'jeu', 'avoir', 'pion', 'papillon', 'plus', 'simple', 'aller', 'tout', 'embêter', 'si', 'autre', 'carte', 'mariposer', 'donc', 'tour', 'pouvoir', 'variante', 'départ', 'tension', 'falloir', 'point', 'déplacement', 'optimiser', 'envie', 'joli', 'essayer', 'très', 'réfléchir', 'ville', 'retourner', 'courbe', 'bon', 'jouer', 'mariposa', 'naissance', 'voyage', 'course', 'partie', 'proche', 'vie', 'action', 'acumuler', 'balad', 'cours', 'deplacmer', 'devoir', 'dire', 'exacerber', 'fil', 'grâce', 'joue', 'mise', 'optimisation', 'pet', 'possibilité', 'remporter', 'setting', 'somme', 'bien', 'apprentissage', 'arriver', 'aussi', 'bel', 'bemol', 'bijou', 'camoufler', 'concerner', 'contribuer', 'couleur', 'cycl', 'différents', 'donne', 'histoire', 'illustration', 'impossible', 'matériel', 'mini', 'oeil', 'parce', 'permettre', 'propo', 'regarder', 'réussite', 'sauver', 'toujours', 'visualiser', 'gagner', 'migration', 'score', 'sembler', 'vraiment', 'maximum', 'mexiqu', 'moins', 'nord', 'ramener', 'reste', 'revenir', 'deux']\n"
     ]
    }
   ],
   "source": [
    "print(tf_idf(comments, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "decoding to str: need a bytes-like object, int found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/martin/Library/Mobile Documents/com~apple~CloudDocs/L3/Projet_recommendation/TESTS_FINAUX.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/martin/Library/Mobile%20Documents/com~apple~CloudDocs/L3/Projet_recommendation/TESTS_FINAUX.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(lda(comments))\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/L3/Projet_recommendation/methodes_nlp.py:54\u001b[0m, in \u001b[0;36mlda\u001b[0;34m(comments, num_topics, num_keywords)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlda\u001b[39m(comments, num_topics\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, num_keywords\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m):\n\u001b[1;32m     52\u001b[0m     \n\u001b[1;32m     53\u001b[0m     \u001b[39m# Create a dictionary and corpus\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     dictionary \u001b[39m=\u001b[39m corpora\u001b[39m.\u001b[39;49mDictionary(comments)\n\u001b[1;32m     55\u001b[0m     corpus \u001b[39m=\u001b[39m [dictionary\u001b[39m.\u001b[39mdoc2bow(comment) \u001b[39mfor\u001b[39;00m comment \u001b[39min\u001b[39;00m comments]\n\u001b[1;32m     57\u001b[0m     \u001b[39m# Train the LDA model\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/lib/python3.9/site-packages/gensim/corpora/dictionary.py:78\u001b[0m, in \u001b[0;36mDictionary.__init__\u001b[0;34m(self, documents, prune_at)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_nnz \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m documents \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_documents(documents, prune_at\u001b[39m=\u001b[39;49mprune_at)\n\u001b[1;32m     79\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_lifecycle_event(\n\u001b[1;32m     80\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcreated\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     81\u001b[0m         msg\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbuilt \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m from \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_docs\u001b[39m}\u001b[39;00m\u001b[39m documents (total \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_pos\u001b[39m}\u001b[39;00m\u001b[39m corpus positions)\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     82\u001b[0m     )\n",
      "File \u001b[0;32m~/micromamba/lib/python3.9/site-packages/gensim/corpora/dictionary.py:204\u001b[0m, in \u001b[0;36mDictionary.add_documents\u001b[0;34m(self, documents, prune_at)\u001b[0m\n\u001b[1;32m    201\u001b[0m         logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39madding document #\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, docno, \u001b[39mself\u001b[39m)\n\u001b[1;32m    203\u001b[0m     \u001b[39m# update Dictionary with the document\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdoc2bow(document, allow_update\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)  \u001b[39m# ignore the result, here we only care about updating token ids\u001b[39;00m\n\u001b[1;32m    206\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mbuilt \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m from \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m documents (total \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m corpus positions)\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_docs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_pos)\n",
      "File \u001b[0;32m~/micromamba/lib/python3.9/site-packages/gensim/corpora/dictionary.py:246\u001b[0m, in \u001b[0;36mDictionary.doc2bow\u001b[0;34m(self, document, allow_update, return_missing)\u001b[0m\n\u001b[1;32m    244\u001b[0m counter \u001b[39m=\u001b[39m defaultdict(\u001b[39mint\u001b[39m)\n\u001b[1;32m    245\u001b[0m \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m document:\n\u001b[0;32m--> 246\u001b[0m     counter[w \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(w, \u001b[39mstr\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39mstr\u001b[39;49m(w, \u001b[39m'\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m'\u001b[39;49m)] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    248\u001b[0m token2id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken2id\n\u001b[1;32m    249\u001b[0m \u001b[39mif\u001b[39;00m allow_update \u001b[39mor\u001b[39;00m return_missing:\n",
      "\u001b[0;31mTypeError\u001b[0m: decoding to str: need a bytes-like object, int found"
     ]
    }
   ],
   "source": [
    "print(lda(comments))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
