{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALGOS DE RECO #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on importe les differentes librairies\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# on importe les différentes librairies surprise de scikit\n",
    "from surprise import SVD\n",
    "from surprise import dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.prediction_algorithms.knns import KNNBasic, KNNWithMeans\n",
    "\n",
    "# on importe notre bdd\n",
    "avis = pd.read_csv(\"BDD/avis.csv\", index_col=\"Unnamed: 0\")\n",
    "jeux = pd.read_csv(\"BDD/jeux.csv\", index_col=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title_review</th>\n",
       "      <th>note</th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monsieur Guillaume</td>\n",
       "      <td>Voyages sur les ailes des papillons</td>\n",
       "      <td>8</td>\n",
       "      <td>Mariposas</td>\n",
       "      <td>Lorsque le jeu est jeu, bon, réflexif, joli po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author                         title_review  note      title  \\\n",
       "0  Monsieur Guillaume  Voyages sur les ailes des papillons     8  Mariposas   \n",
       "\n",
       "                                             comment  \n",
       "0  Lorsque le jeu est jeu, bon, réflexif, joli po...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avis.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut mettre en place la matrice sparse (calculer la sparsité + plot cette sparsite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y'a 2459 auteurs et 3337 jeux\n",
      "Notre matrice a une sparsité de 1.44% \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1x118107 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 117772 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users  = avis[\"author\"].nunique()\n",
    "num_items  = avis[\"title\"].nunique()\n",
    "\n",
    "print(f\"Il y'a {num_users} auteurs et {num_items} jeux\")\n",
    "\n",
    "sparsity = (len(avis) / (num_users*num_items))*100\n",
    "print(f\"Notre matrice a une sparsité de {sparsity:.2f}% \")\n",
    "\n",
    "matrice_sparse = csr_matrix(avis['note'])\n",
    "matrice_sparse\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On test maintenant les differents algos (SVD + KNN pour commencer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.8645  1.8419  1.8639  1.8643  1.8746  1.8618  0.0108  \n",
      "MAE (testset)     1.4342  1.4129  1.4343  1.4335  1.4349  1.4300  0.0085  \n",
      "Fit time          0.72    0.79    0.74    0.72    0.82    0.76    0.04    \n",
      "Test time         0.07    0.07    0.07    0.17    0.07    0.09    0.04    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.86447831, 1.84185635, 1.86390361, 1.86428004, 1.8745915 ]),\n",
       " 'test_mae': array([1.43424344, 1.41288667, 1.43432282, 1.4335127 , 1.43485893]),\n",
       " 'fit_time': (0.7232620716094971,\n",
       "  0.7906975746154785,\n",
       "  0.7410304546356201,\n",
       "  0.7201650142669678,\n",
       "  0.8239736557006836),\n",
       " 'test_time': (0.06754708290100098,\n",
       "  0.0695335865020752,\n",
       "  0.06903648376464844,\n",
       "  0.16936326026916504,\n",
       "  0.07201647758483887)}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SVD()\n",
    "\n",
    "reader = Reader(line_format='user item rating', rating_scale=(0,10))\n",
    "\n",
    "class MyDataset(dataset.DatasetAutoFolds):\n",
    "\n",
    "    def __init__(self, jeux, reader):\n",
    "\n",
    "        self.raw_ratings = [(uid, iid, r, None) for (uid, iid, r) in\n",
    "                            zip(avis['author'], avis['title'], avis['note'])]\n",
    "        self.reader=reader\n",
    "\n",
    "data = MyDataset(jeux, reader)\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.9243  1.8922  1.9211  1.9242  1.8988  1.9121  0.0138  \n",
      "MAE (testset)     1.4846  1.4692  1.4867  1.4951  1.4724  1.4816  0.0095  \n",
      "Fit time          0.39    0.41    0.41    0.42    0.40    0.41    0.01    \n",
      "Test time         0.94    0.95    0.91    0.96    0.90    0.93    0.02    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.92429276, 1.89222614, 1.92111249, 1.92417751, 1.89876231]),\n",
       " 'test_mae': array([1.48456234, 1.46921646, 1.48668215, 1.49510341, 1.47237861]),\n",
       " 'fit_time': (0.38838887214660645,\n",
       "  0.41173720359802246,\n",
       "  0.4122331142425537,\n",
       "  0.41510462760925293,\n",
       "  0.40060949325561523),\n",
       " 'test_time': (0.9362239837646484,\n",
       "  0.945655107498169,\n",
       "  0.9128246307373047,\n",
       "  0.9616246223449707,\n",
       "  0.9030351638793945)}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = KNNBasic()\n",
    "\n",
    "reader = Reader(line_format='user item rating', rating_scale=(0,10))\n",
    "\n",
    "class MyDataset(dataset.DatasetAutoFolds):\n",
    "\n",
    "    def __init__(self, jeux, reader):\n",
    "\n",
    "        self.raw_ratings = [(uid, iid, r, None) for (uid, iid, r) in\n",
    "                            zip(avis['author'], avis['title'], avis['note'])]\n",
    "        self.reader=reader\n",
    "\n",
    "data = MyDataset(jeux, reader)\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
